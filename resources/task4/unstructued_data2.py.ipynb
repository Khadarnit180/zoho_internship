{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "03b62c4b",
   "metadata": {},
   "source": [
    "# unstrctured data to tensors  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "id": "3f0af1bf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Representation of document1:  [[1 0 1 1 1 1 1 1 1 1 1 0]]\n",
      "Representation of document2:  [[0 1 1 0 0 0 0 1 0 1 1 1]]\n",
      "Prediction before training: = tensor([ 4.8704, -0.9766,  4.1053, -2.8953, -5.3855, -4.7503, -0.0432, -2.4552,\n",
      "         2.5648, -3.2575, -0.1290, -4.3337], grad_fn=<AddBackward0>)\n",
      "loss =  tensor(13.6326, grad_fn=<MseLossBackward0>)\n",
      "loss =  tensor(5.6207, grad_fn=<MseLossBackward0>)\n",
      "loss =  tensor(2.3174, grad_fn=<MseLossBackward0>)\n",
      "loss =  tensor(0.9555, grad_fn=<MseLossBackward0>)\n",
      "loss =  tensor(0.3939, grad_fn=<MseLossBackward0>)\n",
      "loss =  tensor(0.1624, grad_fn=<MseLossBackward0>)\n",
      "loss =  tensor(0.0670, grad_fn=<MseLossBackward0>)\n",
      "loss =  tensor(0.0276, grad_fn=<MseLossBackward0>)\n",
      "loss =  tensor(0.0114, grad_fn=<MseLossBackward0>)\n",
      "loss =  tensor(0.0047, grad_fn=<MseLossBackward0>)\n",
      "loss =  tensor(0.0019, grad_fn=<MseLossBackward0>)\n",
      "loss =  tensor(0.0008, grad_fn=<MseLossBackward0>)\n",
      "loss =  tensor(0.0003, grad_fn=<MseLossBackward0>)\n",
      "loss =  tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "loss =  tensor(5.5920e-05, grad_fn=<MseLossBackward0>)\n",
      "loss =  tensor(2.3056e-05, grad_fn=<MseLossBackward0>)\n",
      "\n",
      "model parameterrs for best accuracy ------------------------\n",
      "weight Parameter containing:\n",
      "tensor([[-0.0732],\n",
      "        [-0.0091],\n",
      "        [ 0.3564],\n",
      "        [-0.0873],\n",
      "        [ 0.0382],\n",
      "        [ 0.0675],\n",
      "        [-0.1315],\n",
      "        [ 0.3704],\n",
      "        [-0.1038],\n",
      "        [-0.0257],\n",
      "        [ 0.0149],\n",
      "        [ 0.3055]], requires_grad=True)\n",
      "bias Parameter containing:\n",
      "tensor([ 0.3722,  1.0431, -0.7782,  0.4329, -0.1979, -0.3434,  0.6573, -0.8565,\n",
      "         0.5224,  1.1231,  0.9239, -0.5342], requires_grad=True)\n",
      "\n",
      "hyper parameters- for best accuracy --------------------------------\n",
      "learning rate 0.01 number of epochs: 150\n",
      "Prediction after training: tensor([ 6.0593e-03,  9.9754e-01,  1.0039e+00, -3.6021e-03, -6.7001e-03,\n",
      "        -5.9099e-03, -5.3704e-05,  9.9570e-01,  3.1910e-03,  9.9470e-01,\n",
      "         9.9860e-01,  9.9336e-01], grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "document1 = 'Dog hates a cat It loves to go out and play'\n",
    "document2 = 'Cat loves to play with a ball'\n",
    "\n",
    "# converting sentences to lower case\n",
    "document1 = document1.lower()\n",
    "document2 = document2.lower()\n",
    "\n",
    "# Intialize BoWs\n",
    "count_vect = CountVectorizer()\n",
    "# fit the corpus to CountVectorizer\n",
    "count_vect.fit([document1, document2])\n",
    "\n",
    "#--------print(\"feature names \", count_vect.get_feature_names())\n",
    "\n",
    "# bag of word representation of document1\n",
    "bow1 = count_vect.transform([document1])\n",
    "t1=bow1.toarray()\n",
    "print(\"Representation of document1: \", t1)\n",
    "\n",
    "# bag of word representation of document2\n",
    "bow2 = count_vect.transform([document2])\n",
    "t2=bow2.toarray()\n",
    "print(\"Representation of document2: \", t2)\n",
    "\n",
    "# Output:\n",
    "# feature names  ['and', 'ball', 'cat', 'dog', 'go', 'hates', 'it', 'loves', 'out', 'play', 'to', 'with']\n",
    "\n",
    "# Representation of document1:  [[1 0 1 1 1 1 1 1 1 1 1 0]]\n",
    "# Representation of document2:  [[0 1 1 0 0 0 0 1 0 1 1 1]]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#TRAINING MODEL\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# Linear regression\n",
    "# f = w * x \n",
    "\n",
    "# here : f = 2 * x\n",
    "\n",
    "# X = torch.tensor([[1], [2], [3], [4]], dtype=torch.float32)\n",
    "# Y = torch.tensor([[2], [4], [6], [8]], dtype=torch.float32)\n",
    "X = torch.tensor(t1, dtype=torch.float32)\n",
    "Y = torch.tensor(t2, dtype=torch.float32)\n",
    "# print(Y.shape)\n",
    "# n_samples, n_features = X.shape\n",
    "# print(f'#samples: {n_samples}, #features: {n_features}')\n",
    "# 0) create a test sample\n",
    "#X_test = torch.tensor([5], dtype=torch.float32)\n",
    "\n",
    "# 1) Design Model, the model has to implement the forward pass!\n",
    "# Here we can use a built-in model from PyTorch\n",
    "\n",
    "\n",
    "# we can call this model with samples X\n",
    "model = nn.Linear(1,12)\n",
    "\n",
    "\n",
    "print(f'Prediction before training: = {model(X_test)}')\n",
    "\n",
    "# 2) Define loss and optimizer\n",
    "learning_rate = 0.01\n",
    "n_iters = 151\n",
    "\n",
    "loss = nn.MSELoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# 3) Training loop\n",
    "for epoch in range(n_iters):\n",
    "    # predict = forward pass with our model\n",
    "    y_predicted = model(X_test)\n",
    "\n",
    "    # loss\n",
    "    l = loss(Y, y_predicted)\n",
    "\n",
    "    # calculate gradients = backward pass\n",
    "    l.backward()\n",
    "\n",
    "    # update weights\n",
    "    optimizer.step()\n",
    "\n",
    "    # zero the gradients after updating\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    if epoch % 10 == 0:\n",
    "        print('loss = ', l)\n",
    "print()\n",
    "print(\"model parameterrs for best accuracy ------------------------\")\n",
    "for i,j in model.named_parameters():\n",
    "    print(i,j)\n",
    "print()\n",
    "print(\"hyper parameters- for best accuracy --------------------------------\")\n",
    "print(\"learning rate\",learning_rate,    \"number of epochs:\",epoch)\n",
    "print(f\"Prediction after training: {model(X_test)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51b26e91",
   "metadata": {},
   "source": [
    "# keeping learning rate to half and observing prediction .\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "id": "b03fdc59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " loss =  tensor(2.1101e-05, grad_fn=<MseLossBackward0>)\n",
      " loss =  tensor(1.3616e-05, grad_fn=<MseLossBackward0>)\n",
      " loss =  tensor(8.7860e-06, grad_fn=<MseLossBackward0>)\n",
      " loss =  tensor(5.6693e-06, grad_fn=<MseLossBackward0>)\n",
      " loss =  tensor(3.6583e-06, grad_fn=<MseLossBackward0>)\n",
      " loss =  tensor(2.3605e-06, grad_fn=<MseLossBackward0>)\n",
      " loss =  tensor(1.5232e-06, grad_fn=<MseLossBackward0>)\n",
      " loss =  tensor(9.8285e-07, grad_fn=<MseLossBackward0>)\n",
      " loss =  tensor(6.3424e-07, grad_fn=<MseLossBackward0>)\n",
      " loss =  tensor(4.0926e-07, grad_fn=<MseLossBackward0>)\n",
      " loss =  tensor(2.6409e-07, grad_fn=<MseLossBackward0>)\n",
      " loss =  tensor(1.7041e-07, grad_fn=<MseLossBackward0>)\n",
      " loss =  tensor(1.0998e-07, grad_fn=<MseLossBackward0>)\n",
      " loss =  tensor(7.0979e-08, grad_fn=<MseLossBackward0>)\n",
      " loss =  tensor(4.5806e-08, grad_fn=<MseLossBackward0>)\n",
      " loss =  tensor(2.9536e-08, grad_fn=<MseLossBackward0>)\n",
      "\n",
      "model parameterrs for best accuracy ------------------------\n",
      "weight Parameter containing:\n",
      "tensor([[-0.0743],\n",
      "        [-0.0087],\n",
      "        [ 0.3557],\n",
      "        [-0.0866],\n",
      "        [ 0.0395],\n",
      "        [ 0.0686],\n",
      "        [-0.1315],\n",
      "        [ 0.3712],\n",
      "        [-0.1044],\n",
      "        [-0.0247],\n",
      "        [ 0.0152],\n",
      "        [ 0.3067]], requires_grad=True)\n",
      "bias Parameter containing:\n",
      "tensor([ 0.3719,  1.0432, -0.7783,  0.4331, -0.1976, -0.3432,  0.6573, -0.8564,\n",
      "         0.5223,  1.1233,  0.9239, -0.5340], requires_grad=True)\n",
      "\n",
      "hyper parameters- for best accuracy --------------------------------\n",
      "learning rate 0.005 number of epochs: 150\n",
      "Prediction after training: tensor([ 2.2185e-04,  9.9991e-01,  1.0001e+00, -1.3191e-04, -2.4526e-04,\n",
      "        -2.1631e-04, -2.1458e-06,  9.9984e-01,  1.1677e-04,  9.9981e-01,\n",
      "         9.9995e-01,  9.9976e-01], grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "learning_rate = 0.01/2\n",
    "n_iters = 151\n",
    "\n",
    "loss = nn.MSELoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate) \n",
    "\n",
    "#3) Training loop\n",
    "for epoch in range(n_iters):\n",
    "    # predict = forward pass with our model\n",
    "    y_predicted = model(X_test)\n",
    "\n",
    "    # loss\n",
    "    l = loss(Y, y_predicted)\n",
    "\n",
    "    # calculate gradients = backward pass\n",
    "    l.backward()\n",
    "\n",
    "    # update weights\n",
    "    optimizer.step()\n",
    "\n",
    "    # zero the gradients after updating\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    if epoch % 10 == 0:\n",
    "        print(' loss = ', l)\n",
    "print()\n",
    "print(\"model parameterrs for best accuracy ------------------------\")\n",
    "for i,j in model.named_parameters():\n",
    "    print(i,j)\n",
    "print()\n",
    "print(\"hyper parameters- for best accuracy --------------------------------\")\n",
    "print(\"learning rate\",learning_rate,    \"number of epochs:\",epoch)\n",
    "print(f\"Prediction after training: {model(X_test)}\")\n",
    "\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b908fa5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
