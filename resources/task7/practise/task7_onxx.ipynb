{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fd106400",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/local/ZOHOCORP/abdul-pt6532/miniconda3/envs/py_torch/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/local/ZOHOCORP/abdul-pt6532/miniconda3/envs/py_torch/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=AlexNet_Weights.IMAGENET1K_V1`. You can also use `weights=AlexNet_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exported graph: graph(%actual_input_1 : Float(10, 3, 224, 224, strides=[150528, 50176, 224, 1], requires_grad=0, device=cpu),\n",
      "      %learned_0 : Float(64, 3, 11, 11, strides=[363, 121, 11, 1], requires_grad=1, device=cpu),\n",
      "      %learned_1 : Float(64, strides=[1], requires_grad=1, device=cpu),\n",
      "      %learned_2 : Float(192, 64, 5, 5, strides=[1600, 25, 5, 1], requires_grad=1, device=cpu),\n",
      "      %learned_3 : Float(192, strides=[1], requires_grad=1, device=cpu),\n",
      "      %learned_4 : Float(384, 192, 3, 3, strides=[1728, 9, 3, 1], requires_grad=1, device=cpu),\n",
      "      %learned_5 : Float(384, strides=[1], requires_grad=1, device=cpu),\n",
      "      %learned_6 : Float(256, 384, 3, 3, strides=[3456, 9, 3, 1], requires_grad=1, device=cpu),\n",
      "      %learned_7 : Float(256, strides=[1], requires_grad=1, device=cpu),\n",
      "      %learned_8 : Float(256, 256, 3, 3, strides=[2304, 9, 3, 1], requires_grad=1, device=cpu),\n",
      "      %learned_9 : Float(256, strides=[1], requires_grad=1, device=cpu),\n",
      "      %learned_10 : Float(4096, 9216, strides=[9216, 1], requires_grad=1, device=cpu),\n",
      "      %learned_11 : Float(4096, strides=[1], requires_grad=1, device=cpu),\n",
      "      %learned_12 : Float(4096, 4096, strides=[4096, 1], requires_grad=1, device=cpu),\n",
      "      %learned_13 : Float(4096, strides=[1], requires_grad=1, device=cpu),\n",
      "      %learned_14 : Float(1000, 4096, strides=[4096, 1], requires_grad=1, device=cpu),\n",
      "      %learned_15 : Float(1000, strides=[1], requires_grad=1, device=cpu)):\n",
      "  %/features/features.0/Conv_output_0 : Float(10, 64, 55, 55, strides=[193600, 3025, 55, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[11, 11], pads=[2, 2, 2, 2], strides=[4, 4], onnx_name=\"/features/features.0/Conv\"](%actual_input_1, %learned_0, %learned_1), scope: torchvision.models.alexnet.AlexNet::/torch.nn.modules.container.Sequential::features/torch.nn.modules.conv.Conv2d::features.0 # /home/local/ZOHOCORP/abdul-pt6532/miniconda3/envs/py_torch/lib/python3.10/site-packages/torch/nn/modules/conv.py:458:0\n",
      "  %/features/features.1/Relu_output_0 : Float(10, 64, 55, 55, strides=[193600, 3025, 55, 1], requires_grad=1, device=cpu) = onnx::Relu[onnx_name=\"/features/features.1/Relu\"](%/features/features.0/Conv_output_0), scope: torchvision.models.alexnet.AlexNet::/torch.nn.modules.container.Sequential::features/torch.nn.modules.activation.ReLU::features.1 # /home/local/ZOHOCORP/abdul-pt6532/miniconda3/envs/py_torch/lib/python3.10/site-packages/torch/nn/functional.py:1453:0\n",
      "  %/features/features.2/MaxPool_output_0 : Float(10, 64, 27, 27, strides=[46656, 729, 27, 1], requires_grad=1, device=cpu) = onnx::MaxPool[ceil_mode=0, kernel_shape=[3, 3], pads=[0, 0, 0, 0], strides=[2, 2], onnx_name=\"/features/features.2/MaxPool\"](%/features/features.1/Relu_output_0), scope: torchvision.models.alexnet.AlexNet::/torch.nn.modules.container.Sequential::features/torch.nn.modules.pooling.MaxPool2d::features.2 # /home/local/ZOHOCORP/abdul-pt6532/miniconda3/envs/py_torch/lib/python3.10/site-packages/torch/nn/functional.py:780:0\n",
      "  %/features/features.3/Conv_output_0 : Float(10, 192, 27, 27, strides=[139968, 729, 27, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[5, 5], pads=[2, 2, 2, 2], strides=[1, 1], onnx_name=\"/features/features.3/Conv\"](%/features/features.2/MaxPool_output_0, %learned_2, %learned_3), scope: torchvision.models.alexnet.AlexNet::/torch.nn.modules.container.Sequential::features/torch.nn.modules.conv.Conv2d::features.3 # /home/local/ZOHOCORP/abdul-pt6532/miniconda3/envs/py_torch/lib/python3.10/site-packages/torch/nn/modules/conv.py:458:0\n",
      "  %/features/features.4/Relu_output_0 : Float(10, 192, 27, 27, strides=[139968, 729, 27, 1], requires_grad=1, device=cpu) = onnx::Relu[onnx_name=\"/features/features.4/Relu\"](%/features/features.3/Conv_output_0), scope: torchvision.models.alexnet.AlexNet::/torch.nn.modules.container.Sequential::features/torch.nn.modules.activation.ReLU::features.4 # /home/local/ZOHOCORP/abdul-pt6532/miniconda3/envs/py_torch/lib/python3.10/site-packages/torch/nn/functional.py:1453:0\n",
      "  %/features/features.5/MaxPool_output_0 : Float(10, 192, 13, 13, strides=[32448, 169, 13, 1], requires_grad=1, device=cpu) = onnx::MaxPool[ceil_mode=0, kernel_shape=[3, 3], pads=[0, 0, 0, 0], strides=[2, 2], onnx_name=\"/features/features.5/MaxPool\"](%/features/features.4/Relu_output_0), scope: torchvision.models.alexnet.AlexNet::/torch.nn.modules.container.Sequential::features/torch.nn.modules.pooling.MaxPool2d::features.5 # /home/local/ZOHOCORP/abdul-pt6532/miniconda3/envs/py_torch/lib/python3.10/site-packages/torch/nn/functional.py:780:0\n",
      "  %/features/features.6/Conv_output_0 : Float(10, 384, 13, 13, strides=[64896, 169, 13, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1], onnx_name=\"/features/features.6/Conv\"](%/features/features.5/MaxPool_output_0, %learned_4, %learned_5), scope: torchvision.models.alexnet.AlexNet::/torch.nn.modules.container.Sequential::features/torch.nn.modules.conv.Conv2d::features.6 # /home/local/ZOHOCORP/abdul-pt6532/miniconda3/envs/py_torch/lib/python3.10/site-packages/torch/nn/modules/conv.py:458:0\n",
      "  %/features/features.7/Relu_output_0 : Float(10, 384, 13, 13, strides=[64896, 169, 13, 1], requires_grad=1, device=cpu) = onnx::Relu[onnx_name=\"/features/features.7/Relu\"](%/features/features.6/Conv_output_0), scope: torchvision.models.alexnet.AlexNet::/torch.nn.modules.container.Sequential::features/torch.nn.modules.activation.ReLU::features.7 # /home/local/ZOHOCORP/abdul-pt6532/miniconda3/envs/py_torch/lib/python3.10/site-packages/torch/nn/functional.py:1453:0\n",
      "  %/features/features.8/Conv_output_0 : Float(10, 256, 13, 13, strides=[43264, 169, 13, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1], onnx_name=\"/features/features.8/Conv\"](%/features/features.7/Relu_output_0, %learned_6, %learned_7), scope: torchvision.models.alexnet.AlexNet::/torch.nn.modules.container.Sequential::features/torch.nn.modules.conv.Conv2d::features.8 # /home/local/ZOHOCORP/abdul-pt6532/miniconda3/envs/py_torch/lib/python3.10/site-packages/torch/nn/modules/conv.py:458:0\n",
      "  %/features/features.9/Relu_output_0 : Float(10, 256, 13, 13, strides=[43264, 169, 13, 1], requires_grad=1, device=cpu) = onnx::Relu[onnx_name=\"/features/features.9/Relu\"](%/features/features.8/Conv_output_0), scope: torchvision.models.alexnet.AlexNet::/torch.nn.modules.container.Sequential::features/torch.nn.modules.activation.ReLU::features.9 # /home/local/ZOHOCORP/abdul-pt6532/miniconda3/envs/py_torch/lib/python3.10/site-packages/torch/nn/functional.py:1453:0\n",
      "  %/features/features.10/Conv_output_0 : Float(10, 256, 13, 13, strides=[43264, 169, 13, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1], onnx_name=\"/features/features.10/Conv\"](%/features/features.9/Relu_output_0, %learned_8, %learned_9), scope: torchvision.models.alexnet.AlexNet::/torch.nn.modules.container.Sequential::features/torch.nn.modules.conv.Conv2d::features.10 # /home/local/ZOHOCORP/abdul-pt6532/miniconda3/envs/py_torch/lib/python3.10/site-packages/torch/nn/modules/conv.py:458:0\n",
      "  %/features/features.11/Relu_output_0 : Float(10, 256, 13, 13, strides=[43264, 169, 13, 1], requires_grad=1, device=cpu) = onnx::Relu[onnx_name=\"/features/features.11/Relu\"](%/features/features.10/Conv_output_0), scope: torchvision.models.alexnet.AlexNet::/torch.nn.modules.container.Sequential::features/torch.nn.modules.activation.ReLU::features.11 # /home/local/ZOHOCORP/abdul-pt6532/miniconda3/envs/py_torch/lib/python3.10/site-packages/torch/nn/functional.py:1453:0\n",
      "  %/features/features.12/MaxPool_output_0 : Float(10, 256, 6, 6, strides=[9216, 36, 6, 1], requires_grad=1, device=cpu) = onnx::MaxPool[ceil_mode=0, kernel_shape=[3, 3], pads=[0, 0, 0, 0], strides=[2, 2], onnx_name=\"/features/features.12/MaxPool\"](%/features/features.11/Relu_output_0), scope: torchvision.models.alexnet.AlexNet::/torch.nn.modules.container.Sequential::features/torch.nn.modules.pooling.MaxPool2d::features.12 # /home/local/ZOHOCORP/abdul-pt6532/miniconda3/envs/py_torch/lib/python3.10/site-packages/torch/nn/functional.py:780:0\n",
      "  %/avgpool/AveragePool_output_0 : Float(10, 256, 6, 6, strides=[9216, 36, 6, 1], requires_grad=1, device=cpu) = onnx::AveragePool[kernel_shape=[1, 1], strides=[1, 1], onnx_name=\"/avgpool/AveragePool\"](%/features/features.12/MaxPool_output_0), scope: torchvision.models.alexnet.AlexNet::/torch.nn.modules.pooling.AdaptiveAvgPool2d::avgpool # /home/local/ZOHOCORP/abdul-pt6532/miniconda3/envs/py_torch/lib/python3.10/site-packages/torch/nn/functional.py:1213:0\n",
      "  %/Flatten_output_0 : Float(10, 9216, strides=[9216, 1], requires_grad=1, device=cpu) = onnx::Flatten[axis=1, onnx_name=\"/Flatten\"](%/avgpool/AveragePool_output_0), scope: torchvision.models.alexnet.AlexNet:: # /home/local/ZOHOCORP/abdul-pt6532/miniconda3/envs/py_torch/lib/python3.10/site-packages/torchvision/models/alexnet.py:49:0\n",
      "  %/classifier/classifier.1/Gemm_output_0 : Float(10, 4096, strides=[4096, 1], requires_grad=1, device=cpu) = onnx::Gemm[alpha=1., beta=1., transB=1, onnx_name=\"/classifier/classifier.1/Gemm\"](%/Flatten_output_0, %learned_10, %learned_11), scope: torchvision.models.alexnet.AlexNet::/torch.nn.modules.container.Sequential::classifier/torch.nn.modules.linear.Linear::classifier.1 # /home/local/ZOHOCORP/abdul-pt6532/miniconda3/envs/py_torch/lib/python3.10/site-packages/torch/nn/modules/linear.py:114:0\n",
      "  %/classifier/classifier.2/Relu_output_0 : Float(10, 4096, strides=[4096, 1], requires_grad=1, device=cpu) = onnx::Relu[onnx_name=\"/classifier/classifier.2/Relu\"](%/classifier/classifier.1/Gemm_output_0), scope: torchvision.models.alexnet.AlexNet::/torch.nn.modules.container.Sequential::classifier/torch.nn.modules.activation.ReLU::classifier.2 # /home/local/ZOHOCORP/abdul-pt6532/miniconda3/envs/py_torch/lib/python3.10/site-packages/torch/nn/functional.py:1453:0\n",
      "  %/classifier/classifier.4/Gemm_output_0 : Float(10, 4096, strides=[4096, 1], requires_grad=1, device=cpu) = onnx::Gemm[alpha=1., beta=1., transB=1, onnx_name=\"/classifier/classifier.4/Gemm\"](%/classifier/classifier.2/Relu_output_0, %learned_12, %learned_13), scope: torchvision.models.alexnet.AlexNet::/torch.nn.modules.container.Sequential::classifier/torch.nn.modules.linear.Linear::classifier.4 # /home/local/ZOHOCORP/abdul-pt6532/miniconda3/envs/py_torch/lib/python3.10/site-packages/torch/nn/modules/linear.py:114:0\n",
      "  %/classifier/classifier.5/Relu_output_0 : Float(10, 4096, strides=[4096, 1], requires_grad=1, device=cpu) = onnx::Relu[onnx_name=\"/classifier/classifier.5/Relu\"](%/classifier/classifier.4/Gemm_output_0), scope: torchvision.models.alexnet.AlexNet::/torch.nn.modules.container.Sequential::classifier/torch.nn.modules.activation.ReLU::classifier.5 # /home/local/ZOHOCORP/abdul-pt6532/miniconda3/envs/py_torch/lib/python3.10/site-packages/torch/nn/functional.py:1453:0\n",
      "  %output1 : Float(10, 1000, strides=[1000, 1], requires_grad=1, device=cpu) = onnx::Gemm[alpha=1., beta=1., transB=1, onnx_name=\"/classifier/classifier.6/Gemm\"](%/classifier/classifier.5/Relu_output_0, %learned_14, %learned_15), scope: torchvision.models.alexnet.AlexNet::/torch.nn.modules.container.Sequential::classifier/torch.nn.modules.linear.Linear::classifier.6 # /home/local/ZOHOCORP/abdul-pt6532/miniconda3/envs/py_torch/lib/python3.10/site-packages/torch/nn/modules/linear.py:114:0\n",
      "  return (%output1)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "\n",
    "dummy_input = torch.randn(10, 3, 224, 224,)\n",
    "model = torchvision.models.alexnet(pretrained=True)\n",
    "\n",
    "# Providing input and output names sets the display names for values\n",
    "# within the model's graph. Setting these does not change the semantics\n",
    "# of the graph; it is only for readability.\n",
    "#\n",
    "# The inputs to the network consist of the flat list of inputs (i.e.\n",
    "# the values you would pass to the forward() method) followed by the\n",
    "# flat list of parameters. You can partially specify names, i.e. provide\n",
    "# a list here shorter than the number of inputs to the model, and we will\n",
    "# only set that subset of names, starting from the beginning.\n",
    "input_names = [ \"actual_input_1\" ] + [ \"learned_%d\" % i for i in range(16) ]\n",
    "output_names = [ \"output1\" ]\n",
    "\n",
    "torch.onnx.export(model, dummy_input, \"alexnet.onnx\", verbose=True, input_names=input_names, output_names=output_names)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "573743f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([33968])\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([4.2617e+01, 3.4917e+01, 3.0868e+01,  ..., 4.1892e-03, 4.1811e-03,\n",
      "        4.1904e-03])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import librosa\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def audio_to_magnitude(path):\n",
    "    # Load audio file\n",
    "    audio, sr = librosa.load(path)\n",
    "    \n",
    "    # Convert audio to tensor\n",
    "    audio = torch.tensor(audio, dtype=torch.float32)\n",
    "    print(audio.shape)\n",
    "    # Apply RFFT\n",
    "    audio_fft = torch.fft.rfft(audio)\n",
    "    \n",
    "    # Get magnitude\n",
    "    magnitude = torch.abs(audio_fft)\n",
    "    plt.plot(magnitude.numpy())\n",
    "    plt.title(\"Magnitude of Audio Signal\")\n",
    "    plt.xlabel(\"Sample\")\n",
    "    plt.ylabel(\"Amplitude\")\n",
    "    plt.show()\n",
    "    print(magnitude)\n",
    "    return magnitude\n",
    "\n",
    "audio_path=\"audio.wav\"\n",
    "\n",
    "mag=audio_to_magnitude(audio_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a613175a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def get_magnitude(audio_file):\n",
    "    # Load the audio file\n",
    "    audio, sr = librosa.load(audio_file)\n",
    "\n",
    "    # Convert the audio signal to a PyTorch tensor\n",
    "    audio = torch.from_numpy(audio)\n",
    "\n",
    "    # Calculate the magnitude of the audio signal\n",
    "    magnitude = torch.abs(audio)\n",
    "\n",
    "    # Plot the magnitude of the audio signal\n",
    "    plt.plot(magnitude.numpy())\n",
    "    plt.title(\"Magnitude of Audio Signal\")\n",
    "    plt.xlabel(\"Sample\")\n",
    "    plt.ylabel(\"Amplitude\")\n",
    "    plt.show()\n",
    "\n",
    "    return magnitude\n",
    "\n",
    "# Use the function\n",
    "magnitude = get_magnitude(\"audio.wav\")\n",
    "print(magnitude)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f9c825c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.nn.modules.container.Sequential'>\n",
      "Exported graph: graph(%audio : Float(1, 33968, strides=[33968, 1], requires_grad=0, device=cpu),\n",
      "      %0.weight : Float(1, 33968, strides=[33968, 1], requires_grad=1, device=cpu),\n",
      "      %0.bias : Float(1, strides=[1], requires_grad=1, device=cpu)):\n",
      "  %/0/Gemm_output_0 : Float(1, 1, strides=[1, 1], requires_grad=1, device=cpu) = onnx::Gemm[alpha=1., beta=1., transB=1, onnx_name=\"/0/Gemm\"](%audio, %0.weight, %0.bias), scope: torch.nn.modules.container.Sequential::/torch.nn.modules.linear.Linear::0 # /home/local/ZOHOCORP/abdul-pt6532/miniconda3/envs/py_torch/lib/python3.10/site-packages/torch/nn/modules/linear.py:114:0\n",
      "  %magnitude : Float(1, 1, strides=[1, 1], requires_grad=1, device=cpu) = onnx::Sigmoid[onnx_name=\"/1/Sigmoid\"](%/0/Gemm_output_0), scope: torch.nn.modules.container.Sequential::/torch.nn.modules.activation.Sigmoid::1 # /home/local/ZOHOCORP/abdul-pt6532/miniconda3/envs/py_torch/lib/python3.10/site-packages/torch/nn/modules/activation.py:294:0\n",
      "  return (%magnitude)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import librosa\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.onnx\n",
    "\n",
    "def get_magnitude(audio_file):\n",
    "    # Load the audio file\n",
    "    audio, sr = librosa.load(audio_file)\n",
    "\n",
    "    # Convert the audio signal to a PyTorch tensor\n",
    "    audio = torch.from_numpy(audio)\n",
    "    print(audio.shape())\n",
    "\n",
    "    # Calculate the magnitude of the audio signal\n",
    "    magnitude = torch.abs(audio)\n",
    "\n",
    "    return magnitude\n",
    "\n",
    "def export_to_onnx(audio_file):\n",
    "    # Load the audio file\n",
    "    audio, sr = librosa.load(audio_file)\n",
    "\n",
    "    # Convert the audio signal to a PyTorch tensor\n",
    "    audio = torch.from_numpy(audio).unsqueeze(0)\n",
    "\n",
    "    # Create a PyTorch model\n",
    "    model = torch.nn.Sequential(torch.nn.Linear(33968, 1), torch.nn.Sigmoid())\n",
    "    print(type(model))\n",
    "    # Export the PyTorch model to the ONNX format\n",
    "    torch.onnx.export(model, audio, \"magnitude.onnx\", input_names=[\"audio\"], output_names=[\"magnitude\"],verbose=True)\n",
    "\n",
    "# Use the function\n",
    "export_to_onnx(\"audio.wav\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ddfa167",
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.onnx\n",
    "\n",
    "def get_magnitude(audio_file):\n",
    "#     # Load the audio file\n",
    "#     audio, sr = librosa.load(audio_file)\n",
    "\n",
    "#     # Convert the audio signal to a PyTorch tensor\n",
    "#     audio = torch.from_numpy(audio).unsqueeze(0)\n",
    "\n",
    "#     # Calculate the magnitude of the audio signal\n",
    "    magnitude = torch.abs(audio)\n",
    "    \n",
    "    return magnitude\n",
    "\n",
    "def export_to_onnx(audio_file):\n",
    "    # Load the audio file\n",
    "    audio, sr = librosa.load(audio_file)\n",
    "\n",
    "    # Convert the audio signal to a PyTorch tensor\n",
    "    audio = torch.from_numpy(audio).unsqueeze(0)\n",
    "\n",
    "    # Export the magnitude calculation as an ONNX model\n",
    "    torch.onnx.export(get_magnitude, audio, \"magnitude.onnx\", input_names=[\"audio\"], output_names=[\"magnitude\"])\n",
    "    \n",
    "# Use the function\n",
    "export_to_onnx(\"audio.wav\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6f83d710",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(33968,)\n",
      "torch.Size([1, 33968])\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'function' object has no attribute 'modules'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [9], line 23\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28mtype\u001b[39m(get_magnitude))\n\u001b[1;32m     22\u001b[0m \u001b[38;5;66;03m# Use the function\u001b[39;00m\n\u001b[0;32m---> 23\u001b[0m \u001b[43mexport_to_onnx\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43maudio.wav\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn [9], line 20\u001b[0m, in \u001b[0;36mexport_to_onnx\u001b[0;34m(audio_file)\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28mprint\u001b[39m(audio\u001b[38;5;241m.\u001b[39mshape)\n\u001b[1;32m     19\u001b[0m \u001b[38;5;66;03m# Export the magnitude calculation as an ONNX model\u001b[39;00m\n\u001b[0;32m---> 20\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43monnx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexport\u001b[49m\u001b[43m(\u001b[49m\u001b[43mget_magnitude\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maudio\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmagnitude.onnx\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_names\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43maudio\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_names\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmagnitude\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28mtype\u001b[39m(get_magnitude))\n",
      "File \u001b[0;32m~/miniconda3/envs/py_torch/lib/python3.10/site-packages/torch/onnx/utils.py:504\u001b[0m, in \u001b[0;36mexport\u001b[0;34m(model, args, f, export_params, verbose, training, input_names, output_names, operator_export_type, opset_version, do_constant_folding, dynamic_axes, keep_initializers_as_inputs, custom_opsets, export_modules_as_functions)\u001b[0m\n\u001b[1;32m    186\u001b[0m \u001b[38;5;129m@_beartype\u001b[39m\u001b[38;5;241m.\u001b[39mbeartype\n\u001b[1;32m    187\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mexport\u001b[39m(\n\u001b[1;32m    188\u001b[0m     model: Union[torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mModule, torch\u001b[38;5;241m.\u001b[39mjit\u001b[38;5;241m.\u001b[39mScriptModule, torch\u001b[38;5;241m.\u001b[39mjit\u001b[38;5;241m.\u001b[39mScriptFunction],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    204\u001b[0m     export_modules_as_functions: Union[\u001b[38;5;28mbool\u001b[39m, Collection[Type[torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mModule]]] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    205\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    206\u001b[0m     \u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Exports a model into ONNX format.\u001b[39;00m\n\u001b[1;32m    207\u001b[0m \n\u001b[1;32m    208\u001b[0m \u001b[38;5;124;03m    If ``model`` is not a :class:`torch.jit.ScriptModule` nor a\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    501\u001b[0m \u001b[38;5;124;03m            All errors are subclasses of :class:`errors.OnnxExporterError`.\u001b[39;00m\n\u001b[1;32m    502\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 504\u001b[0m     \u001b[43m_export\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    505\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    506\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    507\u001b[0m \u001b[43m        \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    508\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexport_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    509\u001b[0m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    510\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtraining\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    511\u001b[0m \u001b[43m        \u001b[49m\u001b[43minput_names\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    512\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_names\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    513\u001b[0m \u001b[43m        \u001b[49m\u001b[43moperator_export_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moperator_export_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    514\u001b[0m \u001b[43m        \u001b[49m\u001b[43mopset_version\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mopset_version\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    515\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdo_constant_folding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdo_constant_folding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    516\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdynamic_axes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdynamic_axes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    517\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkeep_initializers_as_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkeep_initializers_as_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    518\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcustom_opsets\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcustom_opsets\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    519\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexport_modules_as_functions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexport_modules_as_functions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    520\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/py_torch/lib/python3.10/site-packages/torch/onnx/utils.py:1506\u001b[0m, in \u001b[0;36m_export\u001b[0;34m(model, args, f, export_params, verbose, training, input_names, output_names, operator_export_type, export_type, opset_version, do_constant_folding, dynamic_axes, keep_initializers_as_inputs, fixed_batch_size, custom_opsets, add_node_names, onnx_shape_inference, export_modules_as_functions)\u001b[0m\n\u001b[1;32m   1501\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(model, (torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mModule, torch\u001b[38;5;241m.\u001b[39mjit\u001b[38;5;241m.\u001b[39mScriptModule)):\n\u001b[1;32m   1502\u001b[0m     module_typenames_to_export_as_functions \u001b[38;5;241m=\u001b[39m _setup_trace_module_map(\n\u001b[1;32m   1503\u001b[0m         model, export_modules_as_functions\n\u001b[1;32m   1504\u001b[0m     )\n\u001b[0;32m-> 1506\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m exporter_context(model, training, verbose):\n\u001b[1;32m   1507\u001b[0m     val_keep_init_as_ip \u001b[38;5;241m=\u001b[39m _decide_keep_init_as_input(\n\u001b[1;32m   1508\u001b[0m         keep_initializers_as_inputs,\n\u001b[1;32m   1509\u001b[0m         operator_export_type,\n\u001b[1;32m   1510\u001b[0m         opset_version,\n\u001b[1;32m   1511\u001b[0m     )\n\u001b[1;32m   1512\u001b[0m     val_add_node_names \u001b[38;5;241m=\u001b[39m _decide_add_node_names(\n\u001b[1;32m   1513\u001b[0m         add_node_names, operator_export_type\n\u001b[1;32m   1514\u001b[0m     )\n",
      "File \u001b[0;32m~/miniconda3/envs/py_torch/lib/python3.10/contextlib.py:135\u001b[0m, in \u001b[0;36m_GeneratorContextManager.__enter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    133\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkwds, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunc\n\u001b[1;32m    134\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 135\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgen\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    136\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m:\n\u001b[1;32m    137\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgenerator didn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt yield\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n",
      "File \u001b[0;32m~/miniconda3/envs/py_torch/lib/python3.10/site-packages/torch/onnx/utils.py:176\u001b[0m, in \u001b[0;36mexporter_context\u001b[0;34m(model, mode, verbose)\u001b[0m\n\u001b[1;32m    173\u001b[0m \u001b[38;5;129m@contextlib\u001b[39m\u001b[38;5;241m.\u001b[39mcontextmanager\n\u001b[1;32m    174\u001b[0m \u001b[38;5;129m@_beartype\u001b[39m\u001b[38;5;241m.\u001b[39mbeartype\n\u001b[1;32m    175\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mexporter_context\u001b[39m(model, mode: _C_onnx\u001b[38;5;241m.\u001b[39mTrainingMode, verbose: \u001b[38;5;28mbool\u001b[39m):\n\u001b[0;32m--> 176\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m select_model_mode_for_export(\n\u001b[1;32m    177\u001b[0m         model, mode\n\u001b[1;32m    178\u001b[0m     ) \u001b[38;5;28;01mas\u001b[39;00m mode_ctx, disable_apex_o2_state_dict_hook(\n\u001b[1;32m    179\u001b[0m         model\n\u001b[1;32m    180\u001b[0m     ) \u001b[38;5;28;01mas\u001b[39;00m apex_ctx, setup_onnx_logging(\n\u001b[1;32m    181\u001b[0m         verbose\n\u001b[1;32m    182\u001b[0m     ) \u001b[38;5;28;01mas\u001b[39;00m log_ctx, diagnostics\u001b[38;5;241m.\u001b[39mcreate_export_diagnostic_context() \u001b[38;5;28;01mas\u001b[39;00m diagnostic_ctx:\n\u001b[1;32m    183\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m (mode_ctx, apex_ctx, log_ctx, diagnostic_ctx)\n",
      "File \u001b[0;32m~/miniconda3/envs/py_torch/lib/python3.10/contextlib.py:135\u001b[0m, in \u001b[0;36m_GeneratorContextManager.__enter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    133\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkwds, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunc\n\u001b[1;32m    134\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 135\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgen\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    136\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m:\n\u001b[1;32m    137\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgenerator didn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt yield\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n",
      "File \u001b[0;32m~/miniconda3/envs/py_torch/lib/python3.10/site-packages/torch/onnx/utils.py:137\u001b[0m, in \u001b[0;36mdisable_apex_o2_state_dict_hook\u001b[0;34m(model)\u001b[0m\n\u001b[1;32m    135\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(model, torch\u001b[38;5;241m.\u001b[39mjit\u001b[38;5;241m.\u001b[39mScriptFunction):\n\u001b[1;32m    136\u001b[0m     model_hooks \u001b[38;5;241m=\u001b[39m {}  \u001b[38;5;66;03m# type: ignore[var-annotated]\u001b[39;00m\n\u001b[0;32m--> 137\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m model\u001b[38;5;241m.\u001b[39mmodules():\n\u001b[1;32m    138\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m key, hook \u001b[38;5;129;01min\u001b[39;00m module\u001b[38;5;241m.\u001b[39m_state_dict_hooks\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m    139\u001b[0m             \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(hook)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mO2StateDictHook\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'function' object has no attribute 'modules'"
     ]
    }
   ],
   "source": [
    "import librosa\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.onnx\n",
    "\n",
    "def get_magnitude(audio):\n",
    "    # Calculate the magnitude of the audio signal\n",
    "    magnitude = torch.abs(audio)\n",
    "    \n",
    "    return magnitude\n",
    "\n",
    "def export_to_onnx(audio_file):\n",
    "    # Load the audio file\n",
    "    audio, sr = librosa.load(audio_file)\n",
    "    print(audio.shape)\n",
    "    # Convert the audio signal to a PyTorch tensor\n",
    "    audio = torch.from_numpy(audio).unsqueeze(0)\n",
    "    print(audio.shape)\n",
    "    # Export the magnitude calculation as an ONNX model\n",
    "    torch.onnx.export(get_magnitude, audio, \"magnitude.onnx\", input_names=[\"audio\"], output_names=[\"magnitude\"])\n",
    "    print(type(get_magnitude))\n",
    "# Use the function\n",
    "export_to_onnx(\"audio.wav\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8c8d386e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Tensor'>\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class MagnitudeModule(nn.Module):\n",
    "    def forward(self, audio):\n",
    "        magnitude = torch.abs(audio)\n",
    "        print(type(magnitude))\n",
    "        \n",
    "        return magnitude\n",
    "\n",
    "def export_to_onnx(audio_file):\n",
    "    # Load audio file\n",
    "    \n",
    "    audio, sr = librosa.load(audio_file)\n",
    "\n",
    "    \n",
    "    \n",
    "    # Convert audio to tensor\n",
    "    audio = torch.from_numpy(audio).unsqueeze(0)\n",
    "    \n",
    "    # Create instance of MagnitudeModule\n",
    "    magnitude_module = MagnitudeModule()\n",
    "    \n",
    "    # Export the magnitude calculation as an ONNX model\n",
    "    torch.onnx.export(magnitude_module, audio, \"magnitude.onnx\", input_names=[\"audio\"], output_names=[\"magnitude\"])\n",
    "\n",
    "export_to_onnx(\"audio.wav\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08afd500",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b826d66",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
